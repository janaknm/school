\documentclass[a4paper,12pt]{article}
\usepackage{amsmath}
\usepackage{fullpage}
\usepackage{color}
\usepackage{enumerate}

\begin{document}
\title{Homework 3}
\author{Matt Forbes}
\date{November 5, 2010}
\maketitle

\newenvironment{indentpar}[1]%
{\begin{list}{}%
         {\setlength{\leftmargin}{#1}}%
         \item[]%
}
{\end{list}}

\section{Problem One}

In an array of numbers with the property given in this problem (each element is at most 1 greater or less than 
it's neighbors), then the following is true:\\

\noindent Given two indices in the array A, say i and n such that A[i] = a, and A[n] = b, then\\ A[k] = x
for some k in i \dots n and x between a and b.\\

\noindent This is true because the array A is 'continous' in the sense that because each element can
only differ from the preceding by at most 1, then to get from A[i] = a, to A[n] = b, you must hit each
value between on the way, in an unknown order.

\subsection*{Psuedo Code}
\begin{verbatim}
def find_z(A, n, z):
    if A[1] == z: return i
    if A[n] == z: return n

    if z is not in A[1] \dots A[n]:
        raise 'bad input!'

    i = 1
    j = i + (n - i)/2   
    while A[j] != z :
        min = A[i]
        max = A[n]
        mid = A[j]

        if min < z < mid:  
            max = mid
            n = j
        else:
            min = mid
            i = j
        
        j = i + (n - i) / 2   
    end while
    
    return j

\end{verbatim}

\subsection*{Loop Invariant}
A[k] = z for some k in i \dots n.

\subsection*{Proof}

\underline{Basis}:

\begin{indentpar}{1cm}
  At the start of the first iteration, the L.I. holds by the problems definition: \( x \le z \le y \)
  where x=A[i] and y=A[n]. 
\end{indentpar}

\noindent \underline{Maintenance}:

\begin{indentpar}{1cm}
  Suppose we are in an iteration of the loop, and the L.I. has held up to this point. Then, at the beginning of
  this loop, A[k] = z for some k in i \dots n. Let j = middle index between i and n. Now, if z is 
  between A[i] and A[j], then there exists an index k between i and j such that A[k] = z. In this case, the
  algorithm sets n = j, and continues. Because z is in this subarray, the L.I. holds after the iteration. Similarly
  with the case that z is between A[j] \dots A[n]. One of these cases must occur because the loop invariant says
  that A[k] = z for some k in i \dots n.
\end{indentpar}

\noindent \underline{Termination}

\begin{indentpar}{1cm}
    In each iteration, A[k] = z for a k in i \dots j, but the gap between i and j is halved, so the loop is 
    guaranteed to complete eventually (even if only one element remains in the subarray). The loop terminates
    when A[j] == z, so we have found our j.
\end{indentpar}

\subsection*{Analysis}

There are two comparisons done each iteration of this loop. So the number of
comparisons (denoted C, and number of elements n) is:

\[C(n) = \left\{
\begin{tabular}{c c}
    \( 2 + C(n/2) \),& for n \(>\) 2 \\
    1,& for n \(\le\) 2\\
\end{tabular}
\right\}\]\\

\noindent This is the same recurrence relation from the last homework, and I found
it to be\\ O(log n).

\section{Problem Two}

\begin{enumerate}[a)]
  \item 
    \begin{align*}
      \text{let } & \text{\(x_i\) be an IRA denoting that the \(i^\text{th}\) guess was correct.}\\
      & \text{X be a random variable denoting the total number of correct guesses}\\
      & \text{E[x] be the expectation of X}\\
      & \text{c be the number of cards in the deck}\\
      & \text{n be the number of guesses}, n \le c\\
    \end{align*}
    \begin{align*}
      Pr\{x_i\}& = \frac{1}{c}\\
      X& = \sum_{i=1}^n x_i\\
      E[X]& = E\left[\sum_{i=1}^n x_i\right]\\
      & = \sum_{i=1}^n E[x_i]\\
      & = \sum_{i=1}^n Pr\{x_i\}\\
      & = \sum_{i=1}^n \frac{1}{c}\\
      & = \frac{n}{c}\\
    \end{align*}

  \item
    In this scenario, the probability of each guess is dependant on how many cards have
    already been flipped over. The probability of guessing the \(i^{th}\) card correctly
    is going to be \(\frac{1}{c-i}\) where c is the number of cards in the deck. 
    Besides that note, the calculation of the expectation of X is the same as
    in part a. So we'll jump ahead a bit.
    \begin{align*}
      E[X]& = \sum_{i=1}^n Pr\{x_i\}\\
      & = \sum_{i=1}^n \frac{1}{c-i}\\
      & \le \sum_{i=1}^n \frac{1}{n-i}\\
      & \le \sum_{i=1}^n \frac{1}{i}\\
      & = O(\log n)\\
    \end{align*}
\end{enumerate}

\section*{Problem 3}

\begin{enumerate}[a)]

  \item
    The search algorithm for this data structure may need to search each individual array
    \(A_i\) to find an element.The elements of each array are only sorted in terms 
    themselves, and are not related to the elements in the other arrays. There are always
    \(\log n\) arrays in the structure, so we would do a binary search on each array 
    until we found the element (or didn't) we were looking for.

    \noindent Each array \(A_i\) has \(2^i\) elements, so a binary search on that
    array would have a running time of \(\log_2(2^i) = i \). The total running time t 
    of the search procedure would be:

    \begin{align*}
      \text{let k}& = \lceil log n \rceil\\
        t& = \sum_{i=0}^k \log_2 2^i\\
        & = \sum_{i=0}^k i\\
        & = \frac{k(k+1)}{2}\\
        & = \frac{1}{2}\left(\log^2 n + \log n\right) \\
        & = O(\log^2 n)
    \end{align*}

  \item Insertion - The basic idea of inserting in to this structure is to start from
    the left and move all of the elements in the 'filled' arrays in to the first
    'empty' array. We keep the sorted order of these elements by doing a sort of 
    merge similar to what merge\_sort performs. By moving the left-most filled elements
    and the element to insert in to the first empty array preserves the properties
    that are defined for this structure.

  \subsection*{Psuedo Code}

  \begin{verbatim}
    // A is the sorted structure 
    // e is element to insert
    // size(A) is number of elements in A
    def insert(A, e):
        n = size(A)
        N = binary representation of n, LSB is N[0]
        j = the index of the first occurence of 0 in N
        ixs = new array sized j-1 elements all set to 0 
        inserted = false
        insert_ix = 0 

        // merge subarrays 
        for i = 1 ... 2^j:
            if not inserted:
               min = e
           
            for ii = 1 ... (j-1):
                ix = ixs[ii] 
                if ix <= 2^(ii)  and  A[ii][ix] < min:
                    min = A[ii][ix]
                    insert_ix = ii
            endfor

            A[j][i] = min

            if min == e:
                inserted = true
            else:
                ixs[insert_ix]++
        endfor
        
        size(A)++
    
    end
        
  \end{verbatim}

  To make analyzing this procedure easier, I have calculated the running time 
  parameterized by the value of j (index of the first 'empty' array). The main 
  loop of the procedure has \(2^j\) iterations, and it's inner loop has \(j-1\) 
  iterations. So the running time is roughly \(j2^j - 2^j\).
  
  \subsection*{Worst Case analysis}

  Using the above calculation, the worst case would be when the first empty array
  is indexed at \(\log n\), which is the largest possible value of j. The running 
  time (T) of that insert would be:
  \begin{align*}
    T& = (\log_2 n)2^{log_2 n} - 2^{log_2 n}\\
    & = n\log n - n \\
    & = O(n\log n)
  \end{align*}

  \subsection*{Amortized Analysis}

  The worst case analysis is a horrible upper bound of what the running time would
  actually be. In this amortized analysis, we will find the running time of performing
  n insertions, and then divide by n to find the average running time of a single
  insertion.

  \noindent The book provides a handy observation that when doing n increments of a
  binary number, the bit \(b_i\) is flipped exactly \(\dfrac{n}{2^i} \)
  times. Well we know what the running time of an insertion based on which bit is 
  flipped, so we can calculate the running time of all n of these insertions. For
  each bit index, we know the running time of an insertion in that state, and how
  many times that happens.

  Running time of n insertions T(n):

  let k = \(\lfloor \log_2 n \rfloor\)
  \begin{align*}
    T(n)& = \sum_{i=1}^k (\dfrac{n}{2^i})(i2^i - 2^i)\\
    &= \sum_{i=1}^k ni - n\\
    &= \sum_{i=1}^k n(i - 1)\\
    &= n\sum_{i=1}^k i - 1\\
    &= n\left(\sum_{i=1}^k i - \sum_{i=1}^k 1\right)\\
    &= n\left( \dfrac{k^2 + k}{2} - k \right)\\
    &= n\left( \dfrac{\log^2 n + \log n}{2} - \log n \right)\\
  \end{align*}

  Average running time of a single insertion T(1):
  \begin{align*}
    T(1)& = \dfrac{T(n)}{n}\\
    &= \dfrac{\log^2 n + \log n}{2} - \log n\\
    &= O(\log^2 n)\\
  \end{align*}

\end{enumerate}

\end{document}

