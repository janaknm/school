\documentclass[a4paper,12pt]{article}
\usepackage{amsmath}
\usepackage{enumerate}

\pagestyle{empty} \setlength{\parindent}{0mm}
\addtolength{\topmargin}{-0.5in} \setlength{\textheight}{9in}
\addtolength{\textwidth}{1in} \addtolength{\oddsidemargin}{-0.5in}

\newenvironment{ind}[1]%
{\begin{list}{}%
         {\setlength{\leftmargin}{#1}}%
       \item[]%
}
{\end{list}}

\begin{document}

Matt Forbes \\
February 2011 \\
CS 400 - AI Indep. Study \\
Chapter 13 Discussion

\section{Uncertainty}
\begin{enumerate}[]
  
  \item In real-world systems, decisions can't be made so simply as
    those in closed, hypothetical environments. As soon as an agent
    ventures out of the safety of discreteness and full observability,
    things get a bit more complex. In this new scenario, the results
    of its actions can't be determined until they have actually been
    executed, introducing risk. Even actions as basic as movement can
    have unforeseen consequences in an uncertain environment. Plans of
    action can not be generated by walking through a search tree,
    because the results of one action have probabilistic
    repercussions..
    
  \item Presented in this chapter, are two modes of probability
    representation: prior probability and conditional
    probability. Definitions of such are directly related to their
    names; prior probability denotes the agent's belief that some
    event is true with absolutely no other knowledge of the
    environment. On the other hand, conditional probability is the
    belief that an event is true given some set of previous knowledge.

  \item An atomic event is the description of the world accounting for
    all propositions/conditions that can be reasoned about. A
    comprehensive table listing all permutations of atomic events is
    called the full join probability distribution. As the number of
    variables in the world grows, this table becomes infeasible to
    represent literally. This is okay, because using techniques
    described in this chapter, we can break down probabilities to much
    simpler expressions using the notion of independence.

  \item Two variables are independent if their values do not influence
    each other. For example, the state of the weather is independent
    of my preference of ice cream flavors. Existence of absolute
    independence between variables is rare, but can reduce the size of
    the full join probability distribution. More interesting, is the
    idea of conditional independence. When two variables are
    independent when the value of a third is known, we can treat them
    as independent. An example of this might be in the following
    situation of driving a car (and crashing): 

    \begin{ind}{0.5in}
      The variables have(whiplash) and have(trafficTicket) are not
      necessarily independent, because if I have a traffic ticket, I
      could have been in an accident where I received whip lash. If I
      \emph{know} I was in an accident, then these two variables are
      now independent. Whether or not it was my fault (and receieved a
      ticket) does not influence whether or not my neck was injured
      (whiplash).
    \end{ind}

\end{enumerate}

\end{document}

    
