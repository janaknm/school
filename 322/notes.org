* DONE register for moodle: password is 21736
* DONE Wed, Apr 27       - Midterm Exam
* DONE Mon, May 9        - Assignment 1
* TODO Mon, May 23       - Assignment 2
* TODO Mon, Jun 6 (10am) - Final Exam


* Models of Concurrency
** Shared Memory
Usually used in languages not designed specifically for
concurrency. This technique is asynchronous, processes don't have to
meet at any point in time. Ada95+ now uses shared memory.
** Rondezvous
Ada's original form of concurrency. It's a bit like synchronization
where a process can't continue until another process has caught
up. Synchronous technique in which processes are not fully
independent.
** Message Passing
Erlang's method.
* Parallel Programming
Multiple operations simultaneously
** Pros
Speed up, sometimes a more natural model

* Hardware
** SISD
Single Instruction stream, Single Data stream. Not inherently built
for parallelism, it uses fetch-decode-execute cycle, which doesn't
lend itself well to parallelism.
** SIMD
Single Instruction stream, Multiple Data stream. Operates on a vector
(array) of data of the same type. Executes the exact same instruction
on each element in the array at the same time by using multiple
processors.
** MISD
Multiple Instruction stream, Single Data stream. Used in
fault-tolerant situations. Execute the same instruction three times on
separate comptuers/processors. After comparing the results, it chooses
the answer which is most frequent. When different algorithms are
available for a single problem, a MISD system can try them all and see
which comes up with the best results.
** MIMD
Multiple Instruction stream, Multiple Data stream. Common architecture
for super computers, networked parallel computers, multi-core
processors. Need a protocol on how sharing data between
processors/computers is handled.
*** Shared Memory
Common memory across a common bus. Processors usually have individual
caches which are 'private.
*** Private Memory
Each pocessor has it's own private memory. 
 
* Concurrent Programming
** Collection of Sequential Processes
Each process has it's own 'thread of control,' it's own registers and
stack. May run on their own processors, on a single processor, or a
combination. When multiple processes on a single processor,
instructions are interleaved. This is done either via the O/S or
through a run-time system.
** Synchronization
When processes depend on each other to continue.

** Shared Resources/Memory
*** Mutual Exclusion
Only one resource can use a shared resource at any given time.
*** Critical Section
Part of the instructions where exclusive use of some resource is
required (where the resource is necessary), such as when using the
shared 5ml spoon.
*** Pre/Post Protocal
Before the critical section where the resource is used, the
pre-protocal negotiates the acquisition of the resource. After the
critical section, the post-protocal safely returns the resource.
*** Deadlock
Four conditions (requirement) for deadlock; Removing one of these
conditions will alleviate possibility of deadlock.
**** Mutual exclusion
**** Hold and wait
Able to hold a shared resource while waiting for another resource.
**** No preemption
Not allowed to steal the resource from another process.
**** Circular wait
Processes waiting on each other to finish using a resource. Adding an
order on resources can prevent this; ie. you must grab a certain
resource first.
*** Atomic Operations
Uninterruptable. Links instructions together so they HAVE to be
executed one after another, no interleaving allowed while they are
executing.
*** Locking/Unlocking Resources
Once a resource is locked, it belongs to the locking process
indefinitely or when it unlocks it.
*** Spinlock
Basically a while loop checking for a resource to be unlocked, and
then locking it when it's free.
*** Liveness
Can a process continue?
* Distributed Computing
** Processes on different computers.
** Communicate via network
** No shared memory, communication by message passing
** Need levels of abstraction
*** Heterogenous systems
*** Network connections
*** Network fail
** Scalability is easy
* Real-Time Systems
** Correctness requires correct answer and timeliness
*** Hard real-time
Late answer is system failure (crashed aircraft).
*** Soft real-time
Late answer is system degradation (lost customers).
*** Firm real-time
Lateness is tolerated to a certain degree.
* Embedded Systems
** No monitor/keyboard/peripherals/etc
** Compose 99% of computer systems
** Interact with environment through sensors (ie. thermometer)
** Output called an actuator (ie. motor)
** Usually hard real-time
* Ada Tasks
** Declaration
Name of task or task type, includes discriminants (which are like
parameters). These discriminants must be discrete (enum, integer,
etc).
** Body
Local declarations and statements to be executed when task is run.
** Not Compilation Unit
Must be enclosed in a procedure, function, or package.
** Lifecycle of a Task
*** Creation
Either elaboration of a declaration (in declaration region) or
dynamically allocated with an access type.
*** Activation
This refers to the declarative part of the task body. Anything can be
here, including other tasks. It is elaborated, which is why there is
this intermediate phase before the task becomes executable. The task's
local variables are allocated on the task's run-time stack.
*** Executable
**** Ready State
Not currently executing anything, but has everything it needs. Moves
to running when the scheduler dispatches it. 
**** Running
Executing statements. If the scheduler has a higher priority task, it
can 'preempt' this task which puts it back in the ready state.
**** Blocked
The task needs some resource that is not currently available. I.e. a
'delay' statement, or needs access to data that is not currently
available.
*** Completed
Either an exception was thrown in the executable stage, or control
reaches end of the task body.
*** Terminated
An exception could be thrown in the creation of the task. Or all
dependent tasks were terminated and the task is in the completed
stage.

** Exceptions in Tasks
*** Handled exceptions behave identically
*** Unhandled Exceptions
No message, no propogation, task DIES silently. Should always have an
exception handler for 'others' in the main task body..
** Aborting Tasks
Simple statement: abort task_name; Not a good idea to use in practice.
** Identification
*** package Ada.Task_Identification
*** Gives access to: private type Task_ID;
Private type gives access to := = /=
*** function Image(task_id_val)
Returns a string of the name of the task
*** function Current_task
Gives the ID of the caller
** Communication
*** Shared Data
**** Mutual Exclusion
When sharing data, only one task should have access to at any given
time.

* Ada Protected Objects
Can only use procedures and functions defined on it, so it would be
classified as a 'limited private' type in Ada.
** Enacapsulate shared data and operations on that data
*** Ada guarantees mutual exclusion to shared data
** Types of Proected Objects
*** Singleton protected object
*** Protected type, and instances of that type
** Structure of these types
*** Specification (operations)
*** Body (implementation)
** Operations on protected objects
Procedures take full control of the object, and no other tasks can
touch the object until the procedure is complete. They have read/write
access. Function only have read access, and can be run concurrently by
multiple tasks. Third type is .....
** Object Locks
Each protected object has two locks: read/write lock or the read-only
lock. Two states of locks are 'active' or 'inactive' and only one lock
can be active at a time. Procedures need both locks to be inactive in
order to execute. Functions only require the read/write lock to be
inactive, because multiple tasks can read at the same time.

** Entry Operation Type
Just like procedures but have barriers that must be passed before
execution is allowed to continue. When a thread calls an entry, it
first grabs the read/write lock, once it has the lock, if the barrier
is false it will give up the lock and get in queue. When barrier is
true it will grab the read/write lock again, and continue with the
execution.
*** Barriers
**** Must be boolean expressions.
**** Can only use variables within the protected object.
**** Evaluation
Evaluated when entry called. Always re-evaluated when that protected
object completes a procedure or entry.
*** Entry Queues
Every protected entry has a queue. A queued entry call has precedence
over all other protected operations (any procedure or function).
*** Number of Tasks Waiting
There is an object attribute called 'count which returns the number of
tasks waiting at the entry barrier.
* Protected Operations
** Body "critical section"
Section of code that requires mutual exclusion, i.e. other tasks may
be waiting for the data as well. In general, this should be as short
as possible and only work with the shared data.
** No-Nos
*** Delay statements, bad manners
*** Calls to other protected operations (deadlock warning)
*** Creation of tasks
*** Calls to subprograms that could possible block (any I/O)
** Requeueing

* Rendezvous (direct/synchronized interaction)
** Values of in and in out parameters passed from client to server
** Client blocked
** Server executes rendezvous code (if any)
** Values of out and in out paramters passed from server to client
** Client and server continue independently, concurrently

* Concurrency Patterns
** Producer-Consumer Problem
*** Definition
Multiple producers and consumers. Producers add data to some buffer,
and consumers take that data.
*** Problem
Producers must wait if the buffer is full, and consumers must wait if
the buffer is empty. These conditions on the procedures availability
for running are called "barriers"
*** Solution (Ada)
In Ada, the third operation type on protected types is "entry" which
behave identically to procedures, but have a barrier associated with
them.


** Semaphore
Old (from '60s) by Edgar Djikstra. It is the original concurrency
control mechanism that provides mutual exclusion to the Critical
Section.
*** Two Operations
**** Wait
Blocks the task until there is an 'open slot' available in the
semaphore (count > 0). When ready, take a slot (decrement count) and
continue.
**** Signal
After executing the Critical Section, release the 'slot' (increment
count) and continue.
** Barrier
Block tasks until a set number of them have arrived
(synchronization). When they have caught up, release them.

* Erlang Concurrecy
** Processes 
*** All within erlang, so creation/destruction is fast
*** Spawned with function spawn(fun)
*** Own PID is found with self()
** Message passing
*** PID ! "message" 
sends a message to PID
*** Should send own PID in message
* Erlang gen_server
** callback module (ie. my_bank)
** interface functions
*** called by the client
ie. new_account, balance, withdraw, deposit, etc.
** callback routines
 these control the server behavior. 
*** init/1
initialize state
*** handle_call/3
*** handle_cast/3
send message to server, no result returned
*** handle_info/3
send a "spontaneous" message to the server
*** terminate
*** code_change
hot swap of functionality
* ETS (Erlang Term Store)
Store massive amount of data with a very efficient interface
** types of storage
*** data is keyed
*** sets (unique keys: overwrites existing)
*** ordered set (unique keys, sorted on key)
*** bag (non-unique keys, must have unique value for each duplicate key)
*** duplicate bag (no real restrictions)
** usage
*** creation: ets:new(Name, [opt]) -> TableId
*** insertion: ets:insert(TableName, X) -> true
*** search: ets:lookup(TableName, Key) -> list of tuples matching Key
*** delete: ets:delete(TableId)
* Erlang Parallel Programming
multicore CPUs. 
** should make lots of processes to keep the CPUs busy
** how to tell erlang to use parallel processing
*** erl -smp +S N
N is number of schedulers (run-time environment)
* Final
** Flynn's Taxonomy
Classification of computer architectures
*** SISD - Single Instruction stream Single Data stream
Wasn't designed for parallelism, uses the fetch-decode-execute cycle,
which.
*** SIMD -
Executes a single instruction on a lot of data simultaneously, think
vector operations. It does this by using a separate processor/core for
each piece of data.
*** MISD - 
Sends the same instruction to multiple processing units, which
interface with just one set of data.
*** MIMD -
Common architecture for super computers, networked parallel computers,
multi-core processors. Sharing data between processing units is the
trickier part, since each has its own data stream.
**** Sharing Data
Processing units usually have private memory only it can access. When
needing to communicate between themselves, there might be a shared
memory bus, which all have access to. Otherwise they employ some sort
of message passing.
** Deadlock, other definitions
*** Deadlock
When 2+ processes are blocked and will never continue because they're
waiting for a resource that will never be available.
**** Conditions for deadlock (all necessary conditions)
Mutual Exclusion
Hold and wait
No preemption (ability to force processes to give up resources)
Circular wait (processes waiting for each other to finish using a resource)
*** Pre/Post Protocol
Pre: negotiations for obtaining a resource
-- critical section --
Post: replacing a resource
*** Synchonization
When processes depend on each other to continue
** Ada task lifecycle
*** Creation
Happens in two ways: elaboration of a declaration (in the declarative
region) OR dynamically created using an access type.
*** Activation
First the task's lacal variables are allocated on the task's run-time
stack, and the task's declarative section is elaborated. In this
stage, child tasks can be created and any arbitrary code executed,
that's what separates this section from the executable stage.
*** Executable
Once in the executable stage, there are three possible states that the
task will bounce around in. 
**** Ready State
NOT executing any instructions at this point. In this state, the task
is waiting for the scheduler to allocate some execution time for it:
this is the only thing keeping the task from executing instructions.
**** Running
Currently executing instructions. If the scheduler is allowed to
preempt tasks, it could bump this one down to the ready state to allow the higher
priority task to grab some CPU time.
**** Blocked
The task is waiting for some resource to become available. Could also
be in a delay statement. Once the delay is over or it was able to take
the resource, it moves on to the ready state.
*** Completed
Reaches this point for one of two reasons: either the task simply
reached the end of the task body, or an exception was raised in the
task.
*** Terminated
Either an exception was thrown in the CREATION stage of the task, or
the task is on the completed stage and all its dependent tasks are
terminated.
** Ada master/child tasks
*** Creation of child tasks
Static tasks (in declarative part) block the parent (in the activation
stage), while dynamic tasks (created in the parent body) block their
parent in their parent's executable stage.
*** Direct Masters
The direct master of any child task is a block structure. This block
structure could be either be a created block scope, a
procedure/function declarative block, or a task body declarative block. 
**** Static Masters
Statically declared tasks are simply direct children of the block in
which they were declared.
**** Dynamic Masters
The direct master of a dynamically created task is NOT the block in
which it is created, but the block in which the task access type was
DECLARED.
*** Indirect Masters
If block B is a direct master of some task T, and block B is a
procedure body or block statement, then the task which executes B is
an indirect master of task T.
** Ada exceptions in tasks
When an exception is thrown in a task, but not handled appropriately,
the entire task just dies quietly, no message is sent to the run-time
system, and nothing is aborted except for the task itself.
** #10: Describe semaphores and show how they can be implemented in ada
A semaphore is a way to control a resource, or multiple resources in a
way which avoids race conditions. The semaphore keeps track of the
number of resources available, and when a thread asks for a resource,
the semaphore will give them one if there are any, otherwise it will
have to wait until one is available.

Ada implementation:

num_resources : constant positive := 10;

type resource is private;
type resource_array is array(positive range <>) of resource;

protected Semaphore is
    entry take (r : out resource);
    procedure replace(r : int resource);
private
    available : natural := num_resources;
    resources : resource_array(num_resources);
end Semaphore;

protected body Semaphore is
    entry take (r : out resource)
      when count > 0 is
    begin
        r := resources(count);
        count := count - 1;
    end take;

    procedure replace(r : in resource) is
    begin
       count := count + 1;
       resources(count) := r;
    end replace;
end Semaphore;
** Ada requeue
The idea of Ada's requeue is that sometimes a call to an entry call
can not be serviced based on the parameters it is called with. An
entry cannot use the parameters passed to it in the barrier, so the
only choice is to continue with the call. Inside the call, we can test
the parameters however we want, and if we can't service the call, we
can requeue the caller to another (or the same) task, so it can wait
until it's requirements are met.
** Resource allocation problem
*** syntax error (entry problem)
*** Entries cannot use parameters in their barriers
To fix this problem, the entry can requeue the caller if requirements
to continue are not met.
** Generic Servers (genserver)
So the generic server framework requires a *callback* module which
provides the application-specific functions: initializing state,
handling a request, etc.
** Middleware
Middleware sits between a distributed application and the OS, giving
an abstract view of OS internal functionality without being specific.
*** Services
**** Naming 
Providing identification for certain services, so that clients can
find and connect to them.
**** Binding
Creating a persistent connection to a service so multiple requests can
be made without multiple reconnects.
**** Transport
Abstracting away the means of communication to a distributed service.
**** Application Protocal
Defining a way of forming messages that will be understood in client
to server communication.
**** Marshalling
Serializing data in to a universally understood fashion so that it can
be shipped across a transportation line, and then recontstructed on
the other end in a way that the receiver can understand and is
consistent with the original data.
**** Actvation and Execution
Registration of services provided by the server and resource
allocation that will be done on the server.
** Distributed Erlang/Ada

